{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RBM_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlmFfClziT1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gwpy\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKu59vdG-HhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "\n",
        "from gwpy.timeseries import TimeSeries\n",
        "import time\n",
        "from gwpy.time import tconvert\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1az67Tco-Qtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzL10Ob0Dy4d",
        "colab_type": "text"
      },
      "source": [
        "# RBM Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXdJjqhR0kdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright (c) 2016 Michal Lukac, Egor Malykh\n",
        "# Todo its an MIT license so we can use it but check whats about the changes and where to credit\n",
        "\n",
        "class RBM:\n",
        "    def __init__(self,\n",
        "                 n_visible,\n",
        "                 n_hidden,\n",
        "                 learning_rate=0.01,\n",
        "                 momentum=0.95,\n",
        "                 xavier_const=1.0,\n",
        "                 err_function='cosine',\n",
        "                 use_tqdm=False):\n",
        "\n",
        "        self.sample_visible = False\n",
        "        self.sigma = 1\n",
        "        if not 0.0 <= momentum <= 1.0:\n",
        "            raise ValueError('momentum should be in range [0, 1]')\n",
        "\n",
        "        if err_function not in {'mse', 'cosine'}:\n",
        "            raise ValueError('err_function should be either \\'mse\\' or \\'cosine\\'')\n",
        "\n",
        "        self._use_tqdm = use_tqdm\n",
        "        self._tqdm = None\n",
        "\n",
        "        if use_tqdm or tqdm is not None:\n",
        "            self._tqdm = tqdm\n",
        "        self.n_visible = n_visible\n",
        "        self.n_hidden = n_hidden\n",
        "        self.learning_rate = learning_rate\n",
        "        self.momentum = momentum\n",
        "\n",
        "        self.x = tf.placeholder(tf.float32, [None, self.n_visible])\n",
        "        self.y = tf.placeholder(tf.float32, [None, self.n_hidden])\n",
        "\n",
        "        self.w = tf.Variable(tf_xavier_init(n_visible, n_hidden), dtype=tf.float32)\n",
        "        self.visible_bias = tf.Variable(tf.zeros([self.n_visible]), dtype=tf.float32)\n",
        "        self.hidden_bias = tf.Variable(tf.zeros([self.n_hidden]), dtype=tf.float32)\n",
        "\n",
        "        self.delta_w = tf.Variable(tf.zeros([self.n_visible, self.n_hidden]), dtype=tf.float32)\n",
        "        self.delta_visible_bias = tf.Variable(tf.zeros([self.n_visible]), dtype=tf.float32)\n",
        "        self.delta_hidden_bias = tf.Variable(tf.zeros([self.n_hidden]), dtype=tf.float32)\n",
        "\n",
        "        self.update_weights = None\n",
        "        self.update_deltas = None\n",
        "        self.compute_hidden = None\n",
        "        self.compute_visible = None\n",
        "        self.compute_visible_from_hidden = None\n",
        "\n",
        "        self._initialize_vars()\n",
        "\n",
        "        assert self.update_weights is not None\n",
        "        assert self.update_deltas is not None\n",
        "        assert self.compute_hidden is not None\n",
        "        assert self.compute_visible is not None\n",
        "        assert self.compute_visible_from_hidden is not None\n",
        "\n",
        "        # Todo change error function\n",
        "        if err_function == 'cosine':\n",
        "            x1_norm = tf.nn.l2_normalize(self.x, 1)\n",
        "            x2_norm = tf.nn.l2_normalize(self.compute_visible, 1)\n",
        "            cos_val = tf.reduce_mean(tf.reduce_sum(tf.math.multiply(x1_norm, x2_norm), 1))\n",
        "            self.compute_err = tf.acos(cos_val) / tf.constant(np.pi)\n",
        "        else:\n",
        "            self.compute_err = tf.reduce_mean(tf.square(self.x - self.compute_visible))\n",
        "\n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(init)\n",
        "\n",
        "    def _initialize_vars(self):\n",
        "        hidden_p = tf.nn.sigmoid(tf.matmul(self.x, self.w) + self.hidden_bias)\n",
        "        visible_recon_p = tf.matmul(sample_bernoulli(hidden_p), tf.transpose(self.w)) + self.visible_bias\n",
        "\n",
        "        if self.sample_visible:\n",
        "            visible_recon_p = sample_gaussian(visible_recon_p, self.sigma)\n",
        "\n",
        "        hidden_recon_p = tf.nn.sigmoid(tf.matmul(visible_recon_p, self.w) + self.hidden_bias)\n",
        "\n",
        "        positive_grad = tf.matmul(tf.transpose(self.x), hidden_p)\n",
        "        negative_grad = tf.matmul(tf.transpose(visible_recon_p), hidden_recon_p)\n",
        "\n",
        "        def f(x_old, x_new):\n",
        "            return self.momentum * x_old + \\\n",
        "                   self.learning_rate * x_new * (1 - self.momentum) / tf.to_float(tf.shape(x_new)[0])\n",
        "\n",
        "        delta_w_new = f(self.delta_w, positive_grad - negative_grad)\n",
        "        delta_visible_bias_new = f(self.delta_visible_bias, tf.reduce_mean(self.x - visible_recon_p, 0))\n",
        "        delta_hidden_bias_new = f(self.delta_hidden_bias, tf.reduce_mean(hidden_p - hidden_recon_p, 0))\n",
        "\n",
        "        update_delta_w = self.delta_w.assign(delta_w_new)\n",
        "        update_delta_visible_bias = self.delta_visible_bias.assign(delta_visible_bias_new)\n",
        "        update_delta_hidden_bias = self.delta_hidden_bias.assign(delta_hidden_bias_new)\n",
        "\n",
        "        update_w = self.w.assign(self.w + delta_w_new)\n",
        "        update_visible_bias = self.visible_bias.assign(self.visible_bias + delta_visible_bias_new)\n",
        "        update_hidden_bias = self.hidden_bias.assign(self.hidden_bias + delta_hidden_bias_new)\n",
        "\n",
        "        self.update_deltas = [update_delta_w, update_delta_visible_bias, update_delta_hidden_bias]\n",
        "        self.update_weights = [update_w, update_visible_bias, update_hidden_bias]\n",
        "\n",
        "        self.compute_hidden = tf.nn.sigmoid(tf.matmul(self.x, self.w) + self.hidden_bias)\n",
        "        self.compute_visible = tf.matmul(self.compute_hidden, tf.transpose(self.w)) + self.visible_bias\n",
        "        self.compute_visible_from_hidden = tf.matmul(self.y, tf.transpose(self.w)) + self.visible_bias\n",
        "\n",
        "    def get_err(self, batch_x):\n",
        "        return self.sess.run(self.compute_err, feed_dict={self.x: batch_x})\n",
        "\n",
        "    def get_free_energy(self, sample):\n",
        "        wx_b = tf.tensordot(sample, self.w) + self.hidden_bias\n",
        "        vbias_term = tf.tensordot(sample, self.visible_bias)\n",
        "        hidden_term = tf.reduce_sum(tf.math.log(1 + tf.math.exp(wx_b)), axis=1)\n",
        "        return -hidden_term - vbias_term\n",
        "\n",
        "    def transform(self, batch_x):\n",
        "        return self.sess.run(self.compute_hidden, feed_dict={self.x: batch_x})\n",
        "\n",
        "    def transform_inv(self, batch_y):\n",
        "        return self.sess.run(self.compute_visible_from_hidden, feed_dict={self.y: batch_y})\n",
        "\n",
        "    def reconstruct(self, batch_x):\n",
        "        return self.sess.run(self.compute_visible, feed_dict={self.x: batch_x})\n",
        "\n",
        "    def partial_fit(self, batch_x):\n",
        "        self.sess.run(self.update_weights + self.update_deltas, feed_dict={self.x: batch_x})\n",
        "\n",
        "    def fit(self,\n",
        "            data_x,\n",
        "            n_epoches=10,\n",
        "            batch_size=10,\n",
        "            shuffle=False,\n",
        "            verbose=True):\n",
        "        assert n_epoches > 0\n",
        "\n",
        "        n_data = data_x.shape[0]\n",
        "\n",
        "        if batch_size > 0:\n",
        "            n_batches = n_data // batch_size + (0 if n_data % batch_size == 0 else 1)\n",
        "        else:\n",
        "            n_batches = 1\n",
        "\n",
        "        if shuffle:\n",
        "            data_x_cpy = data_x.copy()\n",
        "            inds = np.arange(n_data)\n",
        "        else:\n",
        "            data_x_cpy = data_x\n",
        "\n",
        "        errs = []\n",
        "\n",
        "        for e in range(n_epoches):\n",
        "            if verbose and not self._use_tqdm:\n",
        "                print('Epoch: {:d}'.format(e))\n",
        "\n",
        "            epoch_errs = np.zeros((n_batches,))\n",
        "            epoch_errs_ptr = 0\n",
        "\n",
        "            if shuffle:\n",
        "                np.random.shuffle(inds)\n",
        "                data_x_cpy = data_x_cpy[inds]\n",
        "\n",
        "            r_batches = range(n_batches)\n",
        "\n",
        "            if verbose and self._use_tqdm:\n",
        "                r_batches = self._tqdm(r_batches, desc='Epoch: {:d}'.format(e), ascii=True, file=sys.stdout)\n",
        "\n",
        "            for b in r_batches:\n",
        "                batch_x = data_x_cpy[b * batch_size:(b + 1) * batch_size]\n",
        "                self.partial_fit(batch_x)\n",
        "                batch_err = self.get_err(batch_x)\n",
        "                epoch_errs[epoch_errs_ptr] = batch_err\n",
        "                epoch_errs_ptr += 1\n",
        "\n",
        "            if verbose:\n",
        "                err_mean = epoch_errs.mean()\n",
        "                if self._use_tqdm:\n",
        "                    self._tqdm.write('Train error: {:.4f}'.format(err_mean))\n",
        "                    self._tqdm.write('')\n",
        "                else:\n",
        "                    print('Train error: {:.4f}'.format(err_mean))\n",
        "                    print('')\n",
        "                sys.stdout.flush()\n",
        "\n",
        "            errs = np.hstack([errs, epoch_errs])\n",
        "\n",
        "        return errs\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.sess.run(self.w), \\\n",
        "               self.sess.run(self.visible_bias), \\\n",
        "               self.sess.run(self.hidden_bias)\n",
        "\n",
        "    def save_weights(self, filename, name):\n",
        "        saver = tf.train.Saver({name + '_w': self.w,\n",
        "                                name + '_v': self.visible_bias,\n",
        "                                name + '_h': self.hidden_bias})\n",
        "        return saver.save(self.sess, filename)\n",
        "\n",
        "    def set_weights(self, w, visible_bias, hidden_bias):\n",
        "        self.sess.run(self.w.assign(w))\n",
        "        self.sess.run(self.visible_bias.assign(visible_bias))\n",
        "        self.sess.run(self.hidden_bias.assign(hidden_bias))\n",
        "\n",
        "    def load_weights(self, filename, name):\n",
        "        saver = tf.train.Saver({name + '_w': self.w,\n",
        "                                name + '_v': self.visible_bias,\n",
        "                                name + '_h': self.hidden_bias})\n",
        "        saver.restore(self.sess, filename)\n",
        "\n",
        "\n",
        "def tf_xavier_init(fan_in, fan_out, const=1.0, dtype=np.float32):\n",
        "    k = const * np.sqrt(6.0 / (2 + int(fan_out)))\n",
        "    return tf.random_uniform(np.array([fan_in, fan_out]), minval=-k, maxval=k, dtype=dtype)\n",
        "\n",
        "\n",
        "def sample_bernoulli(probs):\n",
        "    return tf.nn.relu(tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n",
        "\n",
        "\n",
        "def sample_gaussian(x, sigma):\n",
        "    return x + tf.random_normal(tf.shape(x), mean=0.0, stddev=sigma, dtype=tf.float32)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JddhON7J0seg",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP4nqpWRwYiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#change the top two parameters (play around with different frequencies, but higher might result in crashed due to memory usage)\n",
        "sample_frequency = 1024\n",
        "n_samples = 1000\n",
        "start = 1187529256\n",
        "\n",
        "def pretty(t):\n",
        "  return tconvert(t).strftime(\"%a, %d %b %Y %H:%M:%S %Z\")\n",
        "\n",
        "def fetch(i=0, start=1126259446, delta=32):\n",
        "  halfdelta=delta/2\n",
        "  s,e=start+(delta*i)-halfdelta, start+(delta*(i+1))-halfdelta\n",
        "  print(\"Fetching data for {0} to {1}\".format(pretty(s), pretty(e)))\n",
        "  hdata = TimeSeries.fetch_open_data('H1', s, e, cache=True)\n",
        "  ldata = TimeSeries.fetch_open_data('L1', s, e, cache=True)\n",
        "  # print(\"{0} points for H, {1} points for L\".format(len(hdata), len(ldata)))\n",
        "  return (hdata, ldata)\n",
        "\n",
        "def filter_gwe(data:TimeSeries):\n",
        "  from gwpy.signal import filter_design\n",
        "  bp = filter_design.bandpass(50, 250, data.sample_rate)\n",
        "  notches = [filter_design.notch(line, data.sample_rate) for line in (60, 120, 180)]\n",
        "  zpk = filter_design.concatenate_zpks(bp, *notches)\n",
        "  filt = data.filter(zpk, filtfilt=True)\n",
        "  data = data.crop(*data.span.contract(1))\n",
        "  filt = filt.crop(*filt.span.contract(1))\n",
        "  resample = filt.resample(sample_frequency)\n",
        "  return resample\n",
        "\n",
        "def scale(data):\n",
        "  avg = np.average(data)\n",
        "  sigma = np.std(data)\n",
        "  return (data - avg) / sigma\n",
        "\n",
        "print(\"Sampling\", n_samples, \"datapoints at\",sample_frequency,\"Hz\")\n",
        "data_h, data_l = fetch(start=start, delta=8)\n",
        "test_sample = filter_gwe(data_h)\n",
        "data_points = len(test_sample)\n",
        "x_train = np.zeros((n_samples,data_points*2))\n",
        "for i in range(1,n_samples):\n",
        "  e = start + (8 * i)\n",
        "  data_h, data_l = fetch(start=e, delta=8)\n",
        "  filt_h = np.asarray(filter_gwe(data_h))\n",
        "  filt_h = scale(filt_h)\n",
        "  filt_l = np.asarray(filter_gwe(data_l))\n",
        "  filt_l = scale(filt_l)\n",
        "  x_train[i,0:len(filt_h)] = filt_h\n",
        "  x_train[i,len(filt_h):] = filt_l\n",
        "  print(i)\n",
        "#   # plt.subplot(3,1,1)\n",
        "#   # plt.plot(data)\n",
        "#   # plt.subplot(3,1,2)\n",
        "#   plt.plot(filt)\n",
        "#   # plt.subplot(3,1,3)\n",
        "#   # (data.spectrogram(3, fftlength=3, overlap=2) ** (1/2.)).plot()\n",
        "#   plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gfVSaMU0xWS",
        "colab_type": "text"
      },
      "source": [
        "# Train RBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kry5plhM01H_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#first parameter is the number of visible units (restriced by data format) & the number of hidden units is the second parameter\n",
        "rbm = RBM((data_points*2), (data_points*3), learning_rate=0.01, momentum=0.95, xavier_const=1.0, use_tqdm=True)\n",
        "rbm.fit(x_train, n_epoches=10, batch_size=10)\n",
        "# Check saving works befor training for a long time!!!\n",
        "rbm.save_weights(filename='ML/rbm-weights', name='rbm-weights')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}